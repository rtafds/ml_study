{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression-2: ridge vs ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最小２乗回帰とリッジ回帰モデルを構築しモデル性能とその中身を比較してみましょう。データはボストン・ハウジングデータを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (506,13)\n",
      "y shape: (506,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "                y\n",
      "count  506.000000\n",
      "mean    22.532806\n",
      "std      9.197104\n",
      "min      5.000000\n",
      "25%     17.025000\n",
      "50%     21.200000\n",
      "75%     25.000000\n",
      "max     50.000000\n",
      "----------------------------------------------------------------------------------------\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT     y  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "# import the data for regression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "\n",
    "# set dataframe\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.describe())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの構築は以下の通りです。ツリー系のアルゴリズム（ランダムフォレストや勾配ブースティングなど）を除き、通常、多くの機械学習モデルは、入力ベクトルのスケールを統一させる必要があります。ここではその処理をPipelineで組み込んだサンプルです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of the OLS model: 0.740608\n",
      "R2 score of the Ridge model: 0.740596\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# make pipelines for modeling\n",
    "pipe_ols = Pipeline([('scl',  StandardScaler()), ('est', LinearRegression())])\n",
    "pipe_ridge = Pipeline([('scl', StandardScaler()), ('est', Ridge())])\n",
    "\n",
    "# build models\n",
    "pipe_ols.fit(X, y.as_matrix().ravel())\n",
    "pipe_ridge.fit(X, y.as_matrix().ravel())\n",
    "\n",
    "# get R2 score\n",
    "y_true = y.as_matrix().ravel()\n",
    "y_pred_ols = pipe_ols.predict(X)\n",
    "y_pred_ridge = pipe_ridge.predict(X)\n",
    "\n",
    "# print the performance\n",
    "print('R2 score of the OLS model: %.6f' % r2_score(y_true, y_pred_ols))\n",
    "print('R2 score of the Ridge model: %.6f' % r2_score(y_true, y_pred_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLSとRidgeのどちらが良い予測モデルかをholdout（交差検証）により検証してみましょう。またtrain_test_splitのランダムシードの値、リッジ回帰のalphaの値を変化させた時（ドフォルトの1.0から10.0などへ）のモデルパフォーマンスや、標準偏回帰係数の総和の変化を見てみましょう。このデータでは、OLSとリッジ回帰に大きな性能差は見られないと思います。ただリッジ回帰のalphaを大きくすると、係数総和が減少していく様子が確認できるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Test Score of OLS : 0.763481\n",
      "Test Score of Ridge : 0.763468\n",
      "-----------------------------------------------------\n",
      "Absolute Sum of coefficient of OLS  model: 22.070732\n",
      "Absolute Sum of coefficient of Ridge  model: 21.717317\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 交差検証のためデータを訓練とテストに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# make pipelines for modeling\n",
    "pipe_ols = Pipeline([('scl',  StandardScaler()), ('est', LinearRegression())])\n",
    "pipe_ridge = Pipeline([('scl', StandardScaler()), ('est', Ridge(alpha=1.0))])\n",
    "\n",
    "# build models\n",
    "pipe_ols.fit(X_train, y_train.as_matrix().ravel())\n",
    "pipe_ridge.fit(X_train, y_train.as_matrix().ravel())\n",
    "\n",
    "# 性能指標の表示\n",
    "print('-----------------------------------------------------')\n",
    "print('Test Score of OLS : %.6f' % r2_score(y_test, pipe_ols.predict(X_test)))\n",
    "print('Test Score of Ridge : %.6f' % r2_score(y_test, pipe_ridge.predict(X_test)))\n",
    "\n",
    "# 回帰係数の総和比較\n",
    "# リッジ回帰の正則化項の役割把握のため（モデルの性能評価ではありません）\n",
    "print('-----------------------------------------------------')\n",
    "print('Absolute Sum of coefficient of OLS  model: %.6f' % np.absolute(pipe_ols.named_steps['est'].coef_).sum())\n",
    "print('Absolute Sum of coefficient of Ridge  model: %.6f' % np.absolute(pipe_ridge.named_steps['est'].coef_).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
