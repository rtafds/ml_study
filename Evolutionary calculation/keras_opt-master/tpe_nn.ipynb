{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPE on Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST training on Keras with Tree-structured Parzen Estimator Approach(TPE)\n",
    "* This notebook runs MNIST training on Keras using TPE to find the best hyper parameters.\n",
    "* The MNIST model here is just a simple one with one input layer, one hidden layer and one output layer, without convolution.\n",
    "* Hyperparameters of the model include the followings:\n",
    "* - output shape of the first layer\n",
    "* - dropout rate of the first layer\n",
    "* - output shape of the second layer\n",
    "* - dropout rate of the second layer\n",
    "* - use batchnormalization or not\n",
    "* - batch size\n",
    "* - number of epochs\n",
    "* - validation rate\n",
    "* I used hyperopt to run TPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "import random\n",
    "from keras.layers import Activation, Dropout, BatchNormalization, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MNIST model\n",
    "* includes data loading function, training function, fit function and evaluation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST class\n",
    "class MNIST():\n",
    "    def __init__(self,\n",
    "                 l1_out=512, \n",
    "                 l2_out=512, \n",
    "                 l1_drop=0.2, \n",
    "                 l2_drop=0.2, \n",
    "                 bn1=0,\n",
    "                 bn2=0,\n",
    "                 batch_size=100, \n",
    "                 epochs=10, \n",
    "                 validation_split=0.1):\n",
    "        self.l1_out = l1_out\n",
    "        self.l2_out = l2_out\n",
    "        self.l1_drop = l1_drop\n",
    "        self.l2_drop = l2_drop\n",
    "        self.bn1 = bn1\n",
    "        self.bn2 = bn2\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.validation_split = validation_split\n",
    "        self.__x_train, self.__x_test, self.__y_train, self.__y_test = self.mnist_data()\n",
    "        self.__model = self.mnist_model()\n",
    "        params = \"\"\"\n",
    "        validation_split:\\t{0}\n",
    "        l1_drop:\\t{1}\n",
    "        l2_drop:\\t{2}\n",
    "        l1_out:\\t{3}\n",
    "        l2_out:\\t{4}\n",
    "        bn1:\\t{5}\n",
    "        bn2:\\t{6}\n",
    "        batch_size:\\t{7}\n",
    "        epochs:\\t{8}\n",
    "        \"\"\".format(self.validation_split,\n",
    "                   self.l1_drop, self.l2_drop,\n",
    "                   self.l1_out, self.l2_out,\n",
    "                   self.bn1, self.bn2,\n",
    "                   self.batch_size, self.epochs)\n",
    "        print(params)\n",
    "        \n",
    "    # load mnist data from keras dataset\n",
    "    def mnist_data(self):\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        X_train = X_train.reshape(60000, 784)\n",
    "        X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        X_train /= 255\n",
    "        X_test /= 255\n",
    "\n",
    "        Y_train = np_utils.to_categorical(y_train, 10)\n",
    "        Y_test = np_utils.to_categorical(y_test, 10)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    # mnist model\n",
    "    def mnist_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.l1_out, input_shape=(784,)))\n",
    "        if self.bn1 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(self.l1_drop))\n",
    "        model.add(Dense(self.l2_out))\n",
    "        if self.bn2 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(self.l2_drop))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    # fit mnist model\n",
    "    def mnist_fit(self):\n",
    "        early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "        \n",
    "        self.__model.fit(self.__x_train, self.__y_train,\n",
    "                       batch_size=self.batch_size,\n",
    "                       epochs=self.epochs,\n",
    "                       verbose=0,\n",
    "                       validation_split=self.validation_split,\n",
    "                       callbacks=[early_stopping])\n",
    "    \n",
    "    # evaluate mnist model\n",
    "    def mnist_evaluate(self):\n",
    "        self.mnist_fit()\n",
    "        \n",
    "        evaluation = self.__model.evaluate(self.__x_test, self.__y_test, batch_size=self.batch_size, verbose=0)\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runner function for the MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to run mnist class\n",
    "def run_mnist(args):\n",
    "    _mnist = MNIST(**args)\n",
    "    mnist_evaluation = _mnist.mnist_evaluate()\n",
    "    print(\"loss:{0} \\t\\t accuracy:{1}\".format(mnist_evaluation[0], mnist_evaluation[1]))\n",
    "    return mnist_evaluation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TPE\n",
    "#### hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperopt_parameters = {\n",
    "    'validation_split': hp.uniform('validation_split', 0.0, 0.3),\n",
    "    'l1_drop': hp.uniform('l1_drop', 0.0, 0.3),\n",
    "    'l2_drop': hp.uniform('l2_drop', 0.0, 0.3),\n",
    "    'l1_out': hp.choice('l1_out', [64, 128, 256, 512, 1024]),\n",
    "    'l2_out': hp.choice('l2_out', [64, 128, 256, 512, 1024]),\n",
    "    'bn1': hp.choice('bn1', [0, 1]),\n",
    "    'bn2': hp.choice('bn2', [0, 1]),\n",
    "    'batch_size': hp.choice('batch_size', [10, 100, 500]),\n",
    "    'epochs': hp.choice('epochs', [5, 10, 20]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        validation_split:\t0.16570745280773105\n",
      "        l1_drop:\t0.10096781255984878\n",
      "        l2_drop:\t0.15115381196276345\n",
      "        l1_out:\t128\n",
      "        l2_out:\t64\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00014: early stopping\n",
      "loss:0.07864332050085068 \t\t accuracy:0.975600004196167\n",
      "\n",
      "        validation_split:\t0.24972794128682058\n",
      "        l1_drop:\t0.27528537158976835\n",
      "        l2_drop:\t0.11792311540238463\n",
      "        l1_out:\t64\n",
      "        l2_out:\t1024\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.10114168524742126 \t\t accuracy:0.9692999929189682\n",
      "\n",
      "        validation_split:\t0.19141501122352375\n",
      "        l1_drop:\t0.10894339915491573\n",
      "        l2_drop:\t0.21922173273437492\n",
      "        l1_out:\t128\n",
      "        l2_out:\t512\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.07896663922845619 \t\t accuracy:0.9762000072002411\n",
      "\n",
      "        validation_split:\t0.2344199627410398\n",
      "        l1_drop:\t0.04215718379387921\n",
      "        l2_drop:\t0.13477226030980943\n",
      "        l1_out:\t512\n",
      "        l2_out:\t64\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.07812764397851424 \t\t accuracy:0.9773000079393387\n",
      "\n",
      "        validation_split:\t0.22055750937270943\n",
      "        l1_drop:\t0.04940213450074834\n",
      "        l2_drop:\t0.2843996347939764\n",
      "        l1_out:\t128\n",
      "        l2_out:\t256\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "loss:0.0801679389574565 \t\t accuracy:0.9769000083208084\n",
      "\n",
      "        validation_split:\t0.010494691808292888\n",
      "        l1_drop:\t0.28511568731162695\n",
      "        l2_drop:\t0.21830378634908393\n",
      "        l1_out:\t256\n",
      "        l2_out:\t128\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00003: early stopping\n",
      "loss:0.08331795972771942 \t\t accuracy:0.9742000013589859\n",
      "\n",
      "        validation_split:\t0.26642534571405\n",
      "        l1_drop:\t0.14152981644179027\n",
      "        l2_drop:\t0.08408436647973572\n",
      "        l1_out:\t64\n",
      "        l2_out:\t256\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.10245447189372499 \t\t accuracy:0.970400003194809\n",
      "\n",
      "        validation_split:\t0.29668447938264475\n",
      "        l1_drop:\t0.22893282555209862\n",
      "        l2_drop:\t0.2673639856649491\n",
      "        l1_out:\t64\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00009: early stopping\n",
      "loss:0.10646785139106214 \t\t accuracy:0.9678999900817871\n",
      "\n",
      "        validation_split:\t0.1852948158639595\n",
      "        l1_drop:\t0.09292976568244336\n",
      "        l2_drop:\t0.0871327496264301\n",
      "        l1_out:\t512\n",
      "        l2_out:\t512\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.07238619308918715 \t\t accuracy:0.9779000014066697\n",
      "\n",
      "        validation_split:\t0.02730359730473515\n",
      "        l1_drop:\t0.2329291081806982\n",
      "        l2_drop:\t0.24458400206651668\n",
      "        l1_out:\t256\n",
      "        l2_out:\t64\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.07452301870983502 \t\t accuracy:0.9763999959826469\n",
      "\n",
      "        validation_split:\t0.03951211721227997\n",
      "        l1_drop:\t0.2965166405828253\n",
      "        l2_drop:\t0.04928811115384511\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00002: early stopping\n",
      "loss:0.090917235203034 \t\t accuracy:0.974899995803833\n",
      "\n",
      "        validation_split:\t0.015007389720776509\n",
      "        l1_drop:\t0.2118301485924331\n",
      "        l2_drop:\t0.026599700917866974\n",
      "        l1_out:\t512\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.06938935928046704 \t\t accuracy:0.9782000064849854\n",
      "\n",
      "        validation_split:\t0.2970909632564384\n",
      "        l1_drop:\t0.04429473542216461\n",
      "        l2_drop:\t0.1504676709015255\n",
      "        l1_out:\t512\n",
      "        l2_out:\t64\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.08448807045351714 \t\t accuracy:0.9724999994039536\n",
      "\n",
      "        validation_split:\t0.09515598297013673\n",
      "        l1_drop:\t0.14214863778799966\n",
      "        l2_drop:\t0.11243593067596204\n",
      "        l1_out:\t128\n",
      "        l2_out:\t256\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.0811868553981185 \t\t accuracy:0.9755000054836274\n",
      "\n",
      "        validation_split:\t0.2393571517512889\n",
      "        l1_drop:\t0.1435388062715325\n",
      "        l2_drop:\t0.2577336778157514\n",
      "        l1_out:\t128\n",
      "        l2_out:\t128\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.08332011640799465 \t\t accuracy:0.9744000059366226\n",
      "\n",
      "        validation_split:\t0.0840015308606655\n",
      "        l1_drop:\t0.2381514179268992\n",
      "        l2_drop:\t0.26041627542296963\n",
      "        l1_out:\t512\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "loss:0.06738863769500313 \t\t accuracy:0.9801000064611435\n",
      "\n",
      "        validation_split:\t0.02744485567313418\n",
      "        l1_drop:\t0.05952755060396381\n",
      "        l2_drop:\t0.16720803638229204\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t512\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00003: early stopping\n",
      "loss:0.06631029974669218 \t\t accuracy:0.9775000065565109\n",
      "\n",
      "        validation_split:\t0.23515815829297465\n",
      "        l1_drop:\t0.146094083282963\n",
      "        l2_drop:\t0.10663739048331128\n",
      "        l1_out:\t512\n",
      "        l2_out:\t256\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.07526082053605933 \t\t accuracy:0.9772000062465668\n",
      "\n",
      "        validation_split:\t0.1769135929088967\n",
      "        l1_drop:\t0.2358571049933987\n",
      "        l2_drop:\t0.06196133358592129\n",
      "        l1_out:\t256\n",
      "        l2_out:\t64\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.08443937638554053 \t\t accuracy:0.975599995970726\n",
      "\n",
      "        validation_split:\t0.25302701906807595\n",
      "        l1_drop:\t0.2801066007361808\n",
      "        l2_drop:\t0.16628139881548998\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t128\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.07238336386990159 \t\t accuracy:0.9790999959707261\n"
     ]
    }
   ],
   "source": [
    "# number of evaluation\n",
    "max_evals = 20\n",
    "# trials instance\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    # function to minimize\n",
    "    run_mnist,\n",
    "    # list of hyperparameters\n",
    "    hyperopt_parameters,\n",
    "    # optimization logic\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials,\n",
    "    # output evaluations\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bn1': 0, 'batch_size': 2, 'l1_drop': 0.05952755060396381, 'epochs': 2, 'l2_out': 3, 'l1_out': 4, 'l2_drop': 0.16720803638229204, 'bn2': 1, 'validation_split': 0.02744485567313418}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
