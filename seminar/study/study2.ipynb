{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK:week-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Work-1]\n",
    "\n",
    "###### Q1. リッジ回帰とはどのようなアルゴリズムか  (OLSとの違いは)?\n",
    "    - リッジ回帰は正則化が考慮されたアルゴリズムで過学習を避ける昨日が内包されている。\n",
    "###### Q2.過学習への対処法を4つあげよ。\n",
    "    - アルゴリズム前:次元圧縮、特徴量選択\n",
    "    - アルゴリズム内:正則化\n",
    "    - アルゴリズム後:交叉検証\n",
    "###### Q3.ランダムフォレストのmax_depthのデフォルトはNoneとなっている。どのような決定木が生成されるか説明せよ。\n",
    "　 　　　- しっかりした木が生成される   #深さに規定がないから\n",
    "    - 深さはデータ次第だが、100%正例/負例になるか、min_samples_split以上のうちは分岐を続ける。\n",
    "    - RFが属するバギングには弱学習器で性能を出せるかという問いはない。\n",
    "###### Q4. sklearnのGradientBoostingRregressorのmax_depthのデフォルトを確認せよ。\n",
    "    - default = 3\n",
    "    - 深さ3の木がデフォルト\n",
    "    - 深さ3が深いのか浅いのかはデータ次第だが、大規模データに対してと考えると浅い設定である。\n",
    "    - 一つの決定木で予測ちを聖地かしようとはなっていない(弱学習器)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of OLS: 0.589201\n",
      "R2 score of Ridge: 0.588120\n",
      "R2 score of RandomForest: 0.706710\n",
      "R2 score of GradinetBoostingRegressor: 0.779037\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "#set dataframe\n",
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns = ['y'])\n",
    "\n",
    "#cross-vaiidation(holdout)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=0)\n",
    "\n",
    "#make pipelines for modeling\n",
    "pipe_ols = Pipeline([('scl', StandardScaler()), ('est', LinearRegression())])\n",
    "pipe_ridge = Pipeline([('scl', StandardScaler()),('est', Ridge(random_state=1))])\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),('est', RandomForestRegressor(random_state=1))])\n",
    "pipe_gbr = Pipeline([('scl', StandardScaler()), ('est', GradientBoostingRegressor(random_state=1))])\n",
    "\n",
    "#build models\n",
    "pipe_ols.fit(X_train,y_train.as_matrix().ravel())\n",
    "pipe_ridge.fit(X_train,y_train.as_matrix().ravel())\n",
    "pipe_rf.fit(X_train,y_train.as_matrix().ravel())\n",
    "pipe_gbr.fit(X_train, y_train.as_matrix().ravel())\n",
    "\n",
    "#get R2 score\n",
    "y_true = y_test.as_matrix().ravel()\n",
    "\n",
    "#print the performance\n",
    "print('R2 score of OLS: %.6f' % r2_score(y_true, pipe_ols.predict(X_test)))\n",
    "print('R2 score of Ridge: %.6f' % r2_score(y_true, pipe_ridge.predict(X_test)))\n",
    "print('R2 score of RandomForest: %.6f' % r2_score(y_true, pipe_rf.predict(X_test)))\n",
    "print('R2 score of GradinetBoostingRegressor: %.6f' % r2_score(y_true, pipe_gbr.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
