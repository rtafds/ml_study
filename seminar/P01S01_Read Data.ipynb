{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本講座で用いる主なサンプルデータの読み込みをまとめました。コードを順に実行し結果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (506,13)\n",
      "y shape: (506,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "             MEDV\n",
      "count  506.000000\n",
      "mean    22.532806\n",
      "std      9.197104\n",
      "min      5.000000\n",
      "25%     17.025000\n",
      "50%     21.200000\n",
      "75%     25.000000\n",
      "max     50.000000\n",
      "----------------------------------------------------------------------------------------\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  MEDV  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n",
      "----------------------------------------------------------------------------------------\n",
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the boston house-prices datase for regression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "\n",
    "# set dataframe\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['MEDV'])\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.describe())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (8523,11)\n",
      "y shape: (8523,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "       Item_Outlet_Sales\n",
      "count        8523.000000\n",
      "mean         2181.288914\n",
      "std          1706.499616\n",
      "min            33.290000\n",
      "25%           834.247400\n",
      "50%          1794.331000\n",
      "75%          3101.296400\n",
      "max         13086.964800\n",
      "----------------------------------------------------------------------------------------\n",
      "Check the null count of the target variable: 0\n",
      "----------------------------------------------------------------------------------------\n",
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
      "0           FDA15         9.30          Low Fat         0.016047   \n",
      "1           DRC01         5.92          Regular         0.019278   \n",
      "2           FDN15        17.50          Low Fat         0.016760   \n",
      "3           FDX07        19.20          Regular         0.000000   \n",
      "4           NCD19         8.93          Low Fat         0.000000   \n",
      "\n",
      "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
      "0                  Dairy  249.8092            OUT049   \n",
      "1            Soft Drinks   48.2692            OUT018   \n",
      "2                   Meat  141.6180            OUT049   \n",
      "3  Fruits and Vegetables  182.0950            OUT010   \n",
      "4              Household   53.8614            OUT013   \n",
      "\n",
      "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
      "0                       1999      Medium               Tier 1   \n",
      "1                       2009      Medium               Tier 3   \n",
      "2                       1999      Medium               Tier 1   \n",
      "3                       1998         NaN               Tier 3   \n",
      "4                       1987        High               Tier 3   \n",
      "\n",
      "         Outlet_Type  Item_Outlet_Sales  \n",
      "0  Supermarket Type1          3735.1380  \n",
      "1  Supermarket Type2           443.4228  \n",
      "2  Supermarket Type1          2097.2700  \n",
      "3      Grocery Store           732.3800  \n",
      "4  Supermarket Type1           994.7052  \n"
     ]
    }
   ],
   "source": [
    "# big mart sales amount for regression\n",
    "# https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./data/av_big_mart_sales_UWu5bXk.csv', header=0)  # headerなしの場合はNoneを指定\n",
    "X = df.iloc[:, :-1]      # 全行対象,最終カラム以外をXとする\n",
    "y = df.iloc[:,[-1]]     # 全行対象,最終カラムをyとする\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.describe())\n",
    "# 目的変数に欠損が含まれているとアルゴリズムが学習できないためチェック\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('Check the null count of the target variable: %i' % y.isnull().sum())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (150,4)\n",
      "y shape: (150,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "y\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  y\n",
      "0                5.1               3.5                1.4               0.2  0\n",
      "1                4.9               3.0                1.4               0.2  0\n",
      "2                4.7               3.2                1.3               0.2  0\n",
      "3                4.6               3.1                1.5               0.2  0\n",
      "4                5.0               3.6                1.4               0.2  0\n",
      "----------------------------------------------------------------------------------------\n",
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and return the iris dataset (classification).\n",
    "# The iris dataset is a classic and very easy multi-class classification dataset.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "\n",
    "# Set dataframe\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.groupby('y').size())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (569,30)\n",
      "y shape: (569,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "y\n",
      "0    212\n",
      "1    357\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871 ...          17.33           184.60      2019.0   \n",
      "1                 0.05667 ...          23.41           158.80      1956.0   \n",
      "2                 0.05999 ...          25.53           152.50      1709.0   \n",
      "3                 0.09744 ...          26.50            98.87       567.7   \n",
      "4                 0.05883 ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  y  \n",
      "0          0.4601                  0.11890  0  \n",
      "1          0.2750                  0.08902  0  \n",
      "2          0.3613                  0.08758  0  \n",
      "3          0.6638                  0.17300  0  \n",
      "4          0.2364                  0.07678  0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load and return the breast cancer wisconsin dataset (classification).\n",
    "# The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "# Set dataframe\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.groupby('y').size())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())\n",
    "# print('----------------------------------------------------------------------------------------')\n",
    "# print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (614,12)\n",
      "y shape: (614,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "Loan_Status\n",
      "N    192\n",
      "Y    422\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------\n",
      "Check the null count of the target variable: 0\n",
      "----------------------------------------------------------------------------------------\n",
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n",
      "----------------------------------------------------------------------------------------\n",
      "   Loan_Status Loan_Status_org\n",
      "0            0               Y\n",
      "1            1               N\n",
      "2            0               Y\n",
      "3            0               Y\n",
      "4            0               Y\n",
      "----------------------------------------------------------------------------------------\n",
      "Loan_Status\n",
      "0    422\n",
      "1    192\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# loan screening data for classification \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/av_loan_u6lujuX_CVtuZ9i.csv', header=0)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, [-1]]\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.groupby(['Loan_Status']).size())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('Check the null count of the target variable: %i' % y.isnull().sum())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())\n",
    "\n",
    "# converting stirng to number\n",
    "# 暗黙的にアルゴリズム側で数値変換してくれるが明示的に実施しておく\n",
    "class_mapping = {'N':1, 'Y':0}\n",
    "y_new = y.copy()\n",
    "y_new.loc[:, 'Loan_Status'] = y_new['Loan_Status'].map(class_mapping)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y_new.join(y,rsuffix='_org').head())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y_new.groupby(['Loan_Status']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
