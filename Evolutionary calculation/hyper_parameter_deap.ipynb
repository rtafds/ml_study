{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## いろんな方法を使ってハイパーパラメータの調整をしてみる(特にGA)\n",
    "参考 : https://qiita.com/cvusk/items/1f3b178f34c39beb29ff\n",
    "### 目的 : Python版のGAの使い方と機械学習におけるハイパーパラメータ調整を一挙に習得し、ついでにベイズ最適化とSMBOと呼ばれる、ハイパーパラメータの調整の為に開発された変分法チックな手法のさわりも学ぶ。\n",
    "個人的に変分法・感度解析系の最適化が好きです。(知らんがな)  \n",
    "ベイス推定かベイズ最適化はどっかで使うと思います。\n",
    "#### 今回は機械学習なのであんまり効果が実感できず、しょぼいかもしれませんが、深層学習だと重宝します。深層学習のパラメータはニューロン数、ドロップアウト率、バッチサイズやエポック数などなど設定するパラメータが死ぬほど多い・広いので重宝します。実際はハイパーパラメータの調整はGAじゃなくてベイズ最適化か、SMBOの方が早くていいです。GAは遅いけど、最適解を見つけやすいのがいいとこなので。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題の設定。めんどくさいのでsklearnの糖尿病患者の診療データを使用します(回帰)  \n",
    "目的変数 : 基準から1年後の疾患進行の定量的尺度  \n",
    "説明変数 : 基本情報、低(高)密度リポタンパク質(コレステロール)、血清測定等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "/usr/local/var/pyenv/versions/anaconda3-5.2.0/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/var/pyenv/versions/anaconda3-5.2.0/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "X shape: (442,10)\n",
      "y shape: (442,1)\n",
      "----------------------------------------------------------------------------------------\n",
      "                y\n",
      "count  442.000000\n",
      "mean   152.133484\n",
      "std     77.093005\n",
      "min     25.000000\n",
      "25%     87.000000\n",
      "50%    140.500000\n",
      "75%    211.500000\n",
      "max    346.000000\n",
      "----------------------------------------------------------------------------------------\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6      y  \n",
      "0 -0.002592  0.019908 -0.017646  151.0  \n",
      "1 -0.039493 -0.068330 -0.092204   75.0  \n",
      "2 -0.002592  0.002864 -0.025930  141.0  \n",
      "3  0.034309  0.022692 -0.009362  206.0  \n",
      "4 -0.002592 -0.031991 -0.046641  135.0  \n"
     ]
    }
   ],
   "source": [
    "# import the date for machine learning\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# データを見るだけ。\n",
    "dataset = load_diabetes()\n",
    "\n",
    "# set dataframe\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "# check the shape\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('y shape: (%i,%i)' %y.shape)\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(y.describe())\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print(X.join(y).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例として早くてわかりやすいSVCでやります。  \n",
    "まず、ハイパーパラメータ(引数)を調べます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import signature\n",
    "sig = signature(LinearSVC)\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'penalty': <Parameter \"penalty='l2'\">,\n",
       "              'loss': <Parameter \"loss='squared_hinge'\">,\n",
       "              'dual': <Parameter \"dual=True\">,\n",
       "              'tol': <Parameter \"tol=0.0001\">,\n",
       "              'C': <Parameter \"C=1.0\">,\n",
       "              'multi_class': <Parameter \"multi_class='ovr'\">,\n",
       "              'fit_intercept': <Parameter \"fit_intercept=True\">,\n",
       "              'intercept_scaling': <Parameter \"intercept_scaling=1\">,\n",
       "              'class_weight': <Parameter \"class_weight=None\">,\n",
       "              'verbose': <Parameter \"verbose=0\">,\n",
       "              'random_state': <Parameter \"random_state=None\">,\n",
       "              'max_iter': <Parameter \"max_iter=1000\">})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まあ、意味はわかりずらいので、documentationをみた方がいいです。    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調整するパラメータ | 説明\n",
    "--- | ---\n",
    "penalty |  罰則項。L1正則化・L2正則化(デフォルト)を選択可\n",
    "loss | 評価関数。ヒンジ損失か二乗ヒンジ(デフォルト)\n",
    "dual | 双対問題を解くか否か(デフォルトはtrue)\n",
    "tol | アルゴリズムの終了条件(default=1e-4)\n",
    "C | ソフトマージンの厳しさを表すパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうやらpenalty, loss, dualの組み合わせが  \n",
    "l2,hinge,True,   l2, squared_hinge, True  \n",
    "l1,squared_hinge, False,  l2, squared_hinge, False  \n",
    "しか許さないみたいですね。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価関数をクラスで定義する。\n",
    "# まあ、こうした方がやりやすいと思う。\n",
    "\n",
    "class LSVC():\n",
    "    def __init__(self,\n",
    "                 penalty='l2',\n",
    "                 loss='squared_hinge',\n",
    "                 dual=True,\n",
    "                 tol=1e-4,\n",
    "                 C=1.0):\n",
    "        self.penalty = penalty\n",
    "        self.loss = loss\n",
    "        self.dual = dual\n",
    "        self.tol = tol\n",
    "        self.C = C\n",
    "        params = \"\"\"\n",
    "        penalty:\\t{0}\n",
    "        loss:\\t{1}\n",
    "        dual:\\t{2}\n",
    "        tol:\\t{3}\n",
    "        C:\\t{4}\n",
    "        \"\"\".format(self.penalty, self.loss,\n",
    "                   self.dual, self.tol,\n",
    "                   self.C)\n",
    "        print(params)\n",
    "\n",
    "    # load diabetes data from sklearn dataset\n",
    "    def get_data(self):\n",
    "        dataset = load_diabetes()\n",
    "        # set dataframe\n",
    "        X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "        y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "        X_train_, X_test_, self.y_train, self.y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "        # standard scaling for modeling\n",
    "        # めんどくさいのでX_trainとかを標準化したものにします。\n",
    "        scl = StandardScaler()\n",
    "        self.X_train = scl.fit_transform(X_train_)\n",
    "        self.X_test = scl.transform(X_test_)\n",
    "\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "\n",
    "    def make_model(self):\n",
    "        self.model = LinearSVC(penalty=self.penalty,loss=self.loss,\n",
    "                         dual=self.dual, tol=self.tol, C=self.C)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    # fit model\n",
    "    def model_fit(self):\n",
    "        self.get_data()\n",
    "        self.make_model()\n",
    "        self.model.fit(self.X_train,self.y_train)\n",
    "\n",
    "    # evaluate model\n",
    "    def model_evaluate(self):\n",
    "        try :\n",
    "            self.model_fit()\n",
    "            evaluation = float(r2_score(self.y_test.as_matrix().ravel(), self.model.predict(self.X_test)))\n",
    "        except ValueError:\n",
    "            evaluation = float(-100)\n",
    "        return evaluation,\n",
    "# まじでこのreturnのカンマを忘れる。\n",
    "# 単目的最適化でweight=(1.0,)としているから必要\n",
    "# function to run mnist class\n",
    "\n",
    "\n",
    "def run_model(individual):\n",
    "\n",
    "    _lsvc = LSVC(penalty=individual[0][0],\n",
    "                 loss=individual[0][1],\n",
    "                 dual=individual[0][2],\n",
    "                 tol=individual[1],\n",
    "                 C=individual[2])\n",
    "    model_evaluation = _lsvc.model_evaluate()\n",
    "    return model_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "creator.create('FitnessMax', base.Fitness, weights =(1.0,) )\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "\n",
    "# defining attributes for individual\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# hyper parameter\n",
    "#toolbox.register(\"penalty\", random.choice, ('l1', 'l2'))\n",
    "#toolbox.register(\"loss\", random.choice, ('hinge', 'squared_hinge'))\n",
    "#toolbox.register(\"dual\", random.choice, (True, False))\n",
    "toolbox.register(\"penalty_loss_dual\", \n",
    "                 random.choice, (('l2','hinge',True),('l2','squared_hinge',True),\n",
    "                             ('l1','squared_hinge',False),('l2','squared_hinge',False)) )\n",
    "toolbox.register(\"tol\", random.uniform, 1e-2, 1e-6)\n",
    "toolbox.register(\"C\", random.uniform, 0, 1000)\n",
    "\n",
    "# register attributes to individual\n",
    "toolbox.register('individual', tools.initCycle, creator.Individual,\n",
    "                 (toolbox.penalty_loss_dual, toolbox.tol,\n",
    "                  toolbox.C),\n",
    "                  n = 1)\n",
    "# individual to population\n",
    "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# 突然変異を定義\n",
    "def mutChoice(individual, indpb):\n",
    "\n",
    "    # ループを諦める。\n",
    "    if random.random() < indpb:\n",
    "        individual[0] = random.choice((('l2','hinge',True),('l2','squared_hinge',True),\n",
    "                             ('l1','squared_hinge',False),('l2','squared_hinge',False)))\n",
    "    if random.random() < indpb:\n",
    "            individual[1] = random.uniform(1e-2, 1e-6)\n",
    "    if random.random() < indpb:\n",
    "            individual[2] = random.uniform(0, 1000)\n",
    "    return individual,\n",
    "\n",
    "# evolution\n",
    "toolbox.register('mate', tools.cxTwoPoint)\n",
    "toolbox.register('mutate', mutChoice, indpb = 0.05)\n",
    "toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "toolbox.register('evaluate', run_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    random.seed(64)\n",
    "       \n",
    "    pop = toolbox.population(n=10)\n",
    "    \n",
    "    hof = tools.HallOfFame(1, similar=np.array_equal)\n",
    "    \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, stats=stats,halloffame=hof)\n",
    "\n",
    "    return pop, stats, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tFalse\n",
      "        tol:\t0.008751614920157491\n",
      "        C:\t612.989361613698\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/var/pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:60: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        penalty:\tl2\n",
      "        loss:\thinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.007965092174156621\n",
      "        C:\t268.64853280867965\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.00920195917472651\n",
      "        C:\t416.7337673905216\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\thinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0007244597822858405\n",
      "        C:\t174.56355024436598\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\thinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.009111872041927952\n",
      "        C:\t29.54361416160878\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tFalse\n",
      "        tol:\t0.006030267829116487\n",
      "        C:\t213.7573979486891\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.004503759908635859\n",
      "        C:\t358.8200771005094\n",
      "        \n",
      "gen\tnevals\tavg       \tstd     \tmin      \tmax     \n",
      "0  \t10    \t-0.0313067\t0.150952\t-0.290186\t0.234679\n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.00920195917472651\n",
      "        C:\t416.7337673905216\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.004503759908635859\n",
      "        C:\t358.8200771005094\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "1  \t8     \t-0.0365714\t0.16081 \t-0.325604\t0.234679\n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\thinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\thinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t83.66591038506866\n",
      "        \n",
      "2  \t10    \t-0.458459 \t0.46213 \t-1.60915 \t-0.00438741\n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0049004854722676265\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t386.30148465642833\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0030141239913079607\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "3  \t7     \t-0.172852 \t0.170687\t-0.408101\t0.207884   \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0005005909187553673\n",
      "        C:\t386.30148465642833\n",
      "        \n",
      "4  \t3     \t-0.15608  \t0.171172\t-0.460497\t0.207884   \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0049004854722676265\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "5  \t6     \t-0.174162 \t0.200287\t-0.651636\t0.207884   \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "6  \t4     \t-0.14289  \t0.207227\t-0.590344\t0.207884   \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "7  \t5     \t-0.0891063\t0.136868\t-0.409747\t0.131826   \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "8  \t5     \t-0.102441 \t0.0991709\t-0.302227\t0.0708499  \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "9  \t8     \t-0.16699  \t0.212432 \t-0.499711\t0.308228   \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t778.191675640411\n",
      "        \n",
      "\n",
      "        penalty:\tl2\n",
      "        loss:\tsquared_hinge\n",
      "        dual:\tTrue\n",
      "        tol:\t0.0027878352960267793\n",
      "        C:\t264.0057520512484\n",
      "        \n",
      "10 \t4     \t-0.0134578\t0.20958  \t-0.34798 \t0.308228   \n"
     ]
    }
   ],
   "source": [
    "pop, stats, hof = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('l2', 'squared_hinge', True), 0.0027878352960267793, 778.191675640411]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hof.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[deap.creator.FitnessMax((0.3082276885918732,))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hof.keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVCではほとんどゴミみたいな数値しか出なかったのに、そこそこのr2スコアで出てきます。一過性のものでないか、実験します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0939021112595102"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "pipe_lsvc = Pipeline([('scl',StandardScaler()),\n",
    "                      ('est',LinearSVC(penalty='l2',loss='squared_hinge', \n",
    "                                       dual=True, tol=0.0027878352960267793,\n",
    "                                      C=778.191675640411))])\n",
    "pipe_lsvc.fit(X_train, y_train)\n",
    "r2_score(y_test.values, pipe_lsvc.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そもそも、LinearSVCではどう頑張ってもこのデータの回帰は不可能のようです。笑  \n",
    "train_test_splitがドンピシャな時だけましなスコアが出ます。\n",
    "全然いい例じゃなかったですね。  \n",
    "train_test_splitのrandom_stateを固定したらいい値は出るでしょうが、それは微妙ですね。過学習になりそうです。  \n",
    "あと、最後のpopの中に割といいやつもいると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "## GradientBoostingでハイパーパラメータを選んで同じようにハイパーパラメータを調整してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingなら、そこそこのスコアは出ます。  \n",
    "そして、GradientBoostingは結構パラメータに影響されやすいけど、ドンピシャにハマると機械学習の中では最高の精度が出ます。  \n",
    "パラメータ選択して、パラメータの数から、popsizeと、gaのループ回数とかをうまく計算時間と照らし合わせて決める感じですね。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
